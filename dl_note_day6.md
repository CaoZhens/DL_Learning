### Day6: Learning Note of Shallow neural networks (Video 1-4)
> 备注：今天的内容主要包括：神经网络的表示、输出和多样本的向量化表示
#### 神经网络
符号表示：  
使用中括号上角标来表示神经网络的层；（注意不要与花括号上角标表示的样本混淆）。  
单个神经网络的计算包括两个步骤：计算$z$；通过$\sigma{(z)}$计算$a$。  
$$z = w^Tx + b$$
$$a = \sigma{(z)}$$

#### 神经网络的表示
- 输入层（第0层）
- 隐藏层
- 输出层
**当我们计算网络的层数时，输入层是不算入总层数内，所以隐藏层是第一层，输出层是第二层。第二个惯例是我们将输入层称为第零层**

#### 神经网络的计算
以单节点计算为基础（两步骤），引申：  
$$z_1^{[1]} = w_1^{[1]T}x + b_1^{[1]}, a_1^{[1]} = \sigma{(z_1^{[1]})}$$
$$z_2^{[1]} = w_2^{[1]T}x + b_2^{[1]}, a_2^{[1]} = \sigma{(z_2^{[1]})}$$
$$z_3^{[1]} = w_3^{[1]T}x + b_3^{[1]}, a_3^{[1]} = \sigma{(z_3^{[1]})}$$
$$z_4^{[1]} = w_4^{[1]T}x + b_4^{[1]}, a_4^{[1]} = \sigma{(z_4^{[1]})}$$

向量化：(纵向堆积变成向量)
$$\mathbf{z}^{[1]} = \mathbf{w}^{[1]T}x + \mathbf{b}^{[1]}, \mathbf{a}^{[1]} = \sigma{(\mathbf{z}^{[1]})}$$
其中：
```python
z.shape = (4, 1)
b.shape = (4, 1)
w.shape = (4, 3) # 以课程为例
```

#### 多样本向量化
$$\mathbf{z}^{[1]} = \mathbf{w}^{[1]T}\mathbf{X} + \mathbf{b}^{[1]}, \mathbf{a}^{[1]} = \sigma{(\mathbf{z}^{[1]})}$$