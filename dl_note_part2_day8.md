# Day8: 超参数调试、Batch正则化和程序框架 Video1-4
> 今天的主要学习内容包括：超参数调试的基本原则； 为超参数选择合理范围； 超参数训练实践； Batch归一化

## 超参数调试的基本原则
深度学习训练时的重要超参数及其优先级  
- 最高：
    - $\alpha$
- 次高：
    - $\beta$(默认值可以设置为0.9)
    - hidden unit's num
    - mini-batch size
- 其它：
    - nn's layer num
    - learning rate decay(学习率衰减)
- 几乎不调整：
    - adam算法 $\beta_1 = 0.9, \beta_2 = 0.999, \epsilon = 10^{-8}$

网格搜索与随机搜索  
在传统机器学习算法中，一般利用网格搜索的方式来调参；  
在深度学习领域，一般使用随机搜索。  

## 为超参数选择合理范围
有些时候，均匀取值的方法并不合理，例如：  
假设搜索超参数$\alpha$（学习速率），假设其值最小是0.0001/最大是1。如果画一条从0.0001到1的数轴，沿其随机均匀取值，那90%的数值将会落在0.1到1之间，结果就是，在0.1到1之间，应用了90%的资源，而在0.0001到0.1之间，只有10%的搜索资源，这看上去不合理。使用对数均匀分布应该更加合理。  
```python
r = np.random.rand() * (-4)
alpha = 10^r
```

另一个例子是给$\beta$取值。用于计算指数的加权平均值。假设$\beta$是0.9到0.999之间的某个值。  
当计算指数的加权平均值时，取0.9就像在10个值中计算平均值，有点类似于计算10天的温度平均值，而取0.999就是在1000个值中取平均。如果在0.9到0.999区间搜索，那就不能用线性均匀取值。

此时$1-\beta$的取值范围是0.1到0.0001区间；与上面类似：  
r = [-3, -1]
1-\beta = 10^r
\beta = 1 - 10^r

## 超参数训练实践：熊猫模式 & 鱼子酱模式
这两种方式的选择，是由拥有的计算资源决定的，如果拥有足够的计算机去平行试验许多模型，那绝对采用鱼子酱方式，尝试许多不同的超参数，看效果怎么样。但在一些应用领域，比如在线广告设置和计算机视觉应用领域，那里的数据太多了，你需要试验大量的模型，所以同时试验大量的模型是很困难的，它的确是依赖于应用的过程。但我看到那些应用熊猫方式多一些的组织，

## 激活函数归一化（batch归一化）
$$z_{norm}^{(i)} = \frac{z^{(i)} - \mu}{\sqrt{\sigma^2 + \epsilon}}$$
